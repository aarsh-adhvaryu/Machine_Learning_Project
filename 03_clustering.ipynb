{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c4e346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# PROJECT: Therapeutic Failure Phenotype Discovery\n",
    "# PHASE: Unsupervised Clustering (Phenotype Discovery)\n",
    "# FINAL VERSION — ALSO PREPARES REAL-WORLD CLUSTER FILE\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Start timer\n",
    "start = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf144090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Pipeline Config Loaded.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# CONFIG\n",
    "# --------------------------------------------------------------\n",
    "BASE_DIR  = r\"D:\\ML_Project\"\n",
    "DATA_DIR  = os.path.join(BASE_DIR, \"data\", \"processed\")\n",
    "MODELS_DIR = os.path.join(BASE_DIR, \"models\")\n",
    "LOG_DIR    = os.path.join(BASE_DIR, \"logs\")\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "SAMPLE_TRAIN_EVAL  = os.path.join(DATA_DIR, \"sample_train_eval.csv\")\n",
    "SAMPLE_REALWORLD   = os.path.join(DATA_DIR, \"sample_realworld_test.csv\")\n",
    "\n",
    "OUTPUT_CLUSTERED      = os.path.join(DATA_DIR, \"PROJECT_CLUSTERED_SEVERITY_DATA.csv\")\n",
    "REALWORLD_CLUSTERED   = os.path.join(DATA_DIR, \"REALWORLD_CLUSTERED.csv\")\n",
    "\n",
    "TFIDF_PATH = os.path.join(MODELS_DIR, \"tfidf_vectorizer.joblib\")\n",
    "SVD_PATH   = os.path.join(MODELS_DIR, \"truncated_svd.joblib\")\n",
    "KMEANS_PATH= os.path.join(MODELS_DIR, \"kmeans_failure_pheno.joblib\")\n",
    "LABELMAP_PATH = os.path.join(MODELS_DIR, \"cluster_label_mapping.csv\")\n",
    "\n",
    "TFIDF_PARAMS = {\n",
    "    \"max_features\": 2000,\n",
    "    \"ngram_range\": (1, 2),\n",
    "    \"min_df\": 15,\n",
    "    \"max_df\": 0.9\n",
    "}\n",
    "\n",
    "SVD_COMPONENTS = 50\n",
    "K_RANGE = range(2, 7)\n",
    "FORCE_K = 3\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(\"Clustering Pipeline Config Loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d4c1481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading sample_train_eval.csv ...\n",
      "Failure rows available: 249,048\n",
      "Train: 199,238 | Holdout: 49,810\n",
      "\n",
      "Fitting TF-IDF...\n",
      "Applying SVD...\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# LOAD TRAIN/EVAL SAMPLE\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\nLoading sample_train_eval.csv ...\")\n",
    "df = pd.read_csv(SAMPLE_TRAIN_EVAL, low_memory=False)\n",
    "\n",
    "df_fail = df[df[\"is_failure\"] == 1].copy()\n",
    "print(f\"Failure rows available: {len(df_fail):,}\")\n",
    "\n",
    "if len(df_fail) < 500:\n",
    "    raise ValueError(\"Not enough failure rows for clustering.\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# TEXT SEVERITY HEURISTIC\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "def categorize_severity(text):\n",
    "    t = str(text).lower()\n",
    "    critical = [\"death\", \"cardiac arrest\", \"respiratory failure\", \"shock\", \"coma\", \"organ failure\"]\n",
    "    hospital = [\"hospital\", \"emergency\", \"infection\", \"pneumonia\", \"sepsis\", \"treatment failure\"]\n",
    "    mild = [\"headache\", \"nausea\", \"vomiting\", \"rash\", \"fatigue\", \"dizziness\"]\n",
    "\n",
    "    if any(x in t for x in critical): return \"Critical_Failure\"\n",
    "    if any(x in t for x in hospital): return \"Hospitalization_Failure\"\n",
    "    if any(x in t for x in mild): return \"SideEffect_Failure\"\n",
    "    return \"SideEffect_Failure\"\n",
    "\n",
    "df_fail[\"severity_category\"] = df_fail[\"all_reaction_pts\"].apply(categorize_severity)\n",
    "\n",
    "weight_map = {\"Critical_Failure\": 3.0, \"Hospitalization_Failure\": 2.0, \"SideEffect_Failure\": 1.0}\n",
    "df_fail[\"severity_weight\"] = df_fail[\"severity_category\"].map(weight_map)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# TRAIN / HOLDOUT SPLIT\n",
    "# --------------------------------------------------------------\n",
    "train_df, holdout_df = train_test_split(\n",
    "    df_fail, test_size=0.20, random_state=RANDOM_STATE,\n",
    "    stratify=df_fail[\"severity_category\"]\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df):,} | Holdout: {len(holdout_df):,}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# TF-IDF + SVD\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\nFitting TF-IDF...\")\n",
    "custom_stopwords = sorted(set(ENGLISH_STOP_WORDS).union({\n",
    "    \"drug\",\"effect\",\"reaction\",\"report\",\"adverse\",\"therapy\",\"patient\",\"suspect\",\"treatment\"\n",
    "}))\n",
    "TFIDF_PARAMS[\"stop_words\"] = custom_stopwords\n",
    "\n",
    "tfidf = TfidfVectorizer(**TFIDF_PARAMS)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(train_df[\"all_reaction_pts\"])\n",
    "X_holdout_tfidf = tfidf.transform(holdout_df[\"all_reaction_pts\"])\n",
    "\n",
    "print(\"Applying SVD...\")\n",
    "svd = TruncatedSVD(n_components=SVD_COMPONENTS, random_state=RANDOM_STATE)\n",
    "X_train_red = svd.fit_transform(X_train_tfidf)\n",
    "X_holdout_red = svd.transform(X_holdout_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a88ff8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating K (silhouette)...\n",
      "K=2 → silhouette=0.3895\n",
      "K=3 → silhouette=0.4526\n",
      "K=4 → silhouette=0.3588\n",
      "K=5 → silhouette=0.3662\n",
      "K=6 → silhouette=0.3577\n",
      "\n",
      "Selected K = 3\n",
      "\n",
      "Saved clustered TRAIN/EVAL dataset → D:\\ML_Project\\data\\processed\\PROJECT_CLUSTERED_SEVERITY_DATA.csv\n",
      "\n",
      "Artifacts saved.\n",
      "\n",
      "Loading REAL-WORLD TEST sample...\n",
      "Applying TF-IDF → SVD → KMeans to real-world data...\n",
      "Saved REAL-WORLD clustered dataset → D:\\ML_Project\\data\\processed\\REALWORLD_CLUSTERED.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# FIND BEST K (unless forced)\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\nEvaluating K (silhouette)...\")\n",
    "\n",
    "sil_scores = {}\n",
    "for k in K_RANGE:\n",
    "    km = KMeans(n_clusters=k, n_init=10,random_state=RANDOM_STATE)\n",
    "    labels = km.fit_predict(X_train_red)\n",
    "    s = silhouette_score(X_train_red, labels)\n",
    "    sil_scores[k] = s\n",
    "    print(f\"K={k} → silhouette={s:.4f}\")\n",
    "\n",
    "best_k = FORCE_K if FORCE_K is not None else max(sil_scores, key=sil_scores.get)\n",
    "print(f\"\\nSelected K = {best_k}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# FINAL KMEANS FIT\n",
    "# --------------------------------------------------------------\n",
    "kmeans = KMeans(n_clusters=best_k, n_init=25, random_state=RANDOM_STATE)\n",
    "\n",
    "train_labels = kmeans.fit_predict(X_train_red)\n",
    "holdout_labels = kmeans.predict(X_holdout_red)\n",
    "\n",
    "train_df[\"failure_phenotype\"] = train_labels\n",
    "holdout_df[\"failure_phenotype\"] = holdout_labels\n",
    "\n",
    "label_map = {i: f\"Cluster_{i}\" for i in range(best_k)}\n",
    "train_df[\"failure_phenotype_label\"] = train_df[\"failure_phenotype\"].map(label_map)\n",
    "holdout_df[\"failure_phenotype_label\"] = holdout_df[\"failure_phenotype\"].map(label_map)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# SAVE CLUSTERED TRAIN+HOLDOUT\n",
    "# --------------------------------------------------------------\n",
    "combined = pd.concat([train_df, holdout_df], ignore_index=True)\n",
    "combined.to_csv(OUTPUT_CLUSTERED, index=False)\n",
    "\n",
    "print(f\"\\nSaved clustered TRAIN/EVAL dataset → {OUTPUT_CLUSTERED}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# SAVE CLUSTERING ARTIFACTS\n",
    "# --------------------------------------------------------------\n",
    "joblib.dump(tfidf, TFIDF_PATH)\n",
    "joblib.dump(svd,   SVD_PATH)\n",
    "joblib.dump(kmeans, KMEANS_PATH)\n",
    "pd.Series(label_map).to_csv(LABELMAP_PATH)\n",
    "\n",
    "print(\"\\nArtifacts saved.\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# REAL-WORLD CLUSTERING (NO LEAKAGE)\n",
    "# --------------------------------------------------------------\n",
    "print(\"\\nLoading REAL-WORLD TEST sample...\")\n",
    "df_real = pd.read_csv(SAMPLE_REALWORLD, low_memory=False)\n",
    "\n",
    "if \"all_reaction_pts\" not in df_real:\n",
    "    raise KeyError(\"real-world sample missing 'all_reaction_pts' column.\")\n",
    "\n",
    "print(\"Applying TF-IDF → SVD → KMeans to real-world data...\")\n",
    "\n",
    "real_tfidf = tfidf.transform(df_real[\"all_reaction_pts\"].astype(str))\n",
    "real_svd   = svd.transform(real_tfidf)\n",
    "real_clusters = kmeans.predict(real_svd)\n",
    "\n",
    "df_real[\"failure_phenotype\"] = real_clusters\n",
    "df_real[\"failure_phenotype_label\"] = df_real[\"failure_phenotype\"].map(label_map)\n",
    "\n",
    "df_real.to_csv(REALWORLD_CLUSTERED, index=False)\n",
    "\n",
    "print(f\"Saved REAL-WORLD clustered dataset → {REALWORLD_CLUSTERED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e8d3d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CLUSTERING SUMMARY\n",
      "===================\n",
      "Train failures: 199,238\n",
      "Holdout failures: 49,810\n",
      "Final K: 3\n",
      "\n",
      "Silhouette (train):    0.4526\n",
      "Silhouette (combined): 0.4526\n",
      "\n",
      "Runtime: 2369.21 seconds\n",
      "\n",
      "Clustering pipeline complete.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# SILHOUETTE SUMMARY\n",
    "# --------------------------------------------------------------\n",
    "sil_train = silhouette_score(X_train_red, train_labels)\n",
    "sil_all   = silhouette_score(\n",
    "    np.vstack([X_train_red, X_holdout_red]),\n",
    "    np.concatenate([train_labels, holdout_labels])\n",
    ")\n",
    "\n",
    "summary = f\"\"\"\n",
    "CLUSTERING SUMMARY\n",
    "===================\n",
    "Train failures: {len(train_df):,}\n",
    "Holdout failures: {len(holdout_df):,}\n",
    "Final K: {best_k}\n",
    "\n",
    "Silhouette (train):    {sil_train:.4f}\n",
    "Silhouette (combined): {sil_all:.4f}\n",
    "\n",
    "Runtime: {round(time.time() - start, 2)} seconds\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "with open(os.path.join(LOG_DIR, \"clustering_summary.txt\"), \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"Clustering pipeline complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
